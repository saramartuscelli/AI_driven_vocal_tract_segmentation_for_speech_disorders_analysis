{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Notebook setup"
      ],
      "metadata": {
        "id": "xWBEduuex1CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIjGfRk-GhDO",
        "outputId": "ef257f30-2743-45bb-c802-c33c4e785760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz5iaH2c_c9X"
      },
      "outputs": [],
      "source": [
        "# Possible useful dependencies\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "import tensorflow.keras.layers as tfkl\n",
        "import keras\n",
        "from datetime import datetime\n",
        "from dateutil.tz import gettz\n",
        "import scipy\n",
        "import cv2\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "id": "bL0ozo4Rx9Du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/vocal_tract_segmentation/Dataset_new_new\""
      ],
      "metadata": {
        "id": "wGfI3-GNFqw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "images11 = np.load(dataset_path + \"/s1_micro_images.npz\")['images'] #100\n",
        "labels11 = np.load(dataset_path + \"/s1_micro_labels.npz\")['labels']\n",
        "images12 = np.load(dataset_path + \"/s1_segre_images.npz\")['images']#100\n",
        "labels12 = np.load(dataset_path + \"/s1_segre_labels.npz\")['labels']\n",
        "images13 = np.load(dataset_path + \"/s1_top_images.npz\")['images'] #80\n",
        "labels13 = np.load(dataset_path + \"/s1_top_labels.npz\")['labels']\n",
        "\n",
        "images21 = np.load(dataset_path + \"/s2_micro_images.npz\")['images'] #80\n",
        "labels21 = np.load(dataset_path + \"/s2_micro_labels.npz\")['labels']\n",
        "images22 = np.load(dataset_path + \"/s2_segre_images.npz\")['images'] #100\n",
        "labels22 = np.load(dataset_path + \"/s2_segre_labels.npz\")['labels']\n",
        "images23 = np.load(dataset_path + \"/s2_top_images.npz\")['images'] #60\n",
        "labels23 = np.load(dataset_path + \"/s2_top_labels.npz\")['labels']\n",
        "\n",
        "images41 = np.load(dataset_path + \"/s4_micro_images.npz\")['images'] #50\n",
        "labels41= np.load(dataset_path + \"/s4_micro_labels.npz\")['labels']\n",
        "images42= np.load(dataset_path + \"/s4_pata_images.npz\")['images'] #50\n",
        "labels42 = np.load(dataset_path + \"/s4_pata_labels.npz\")['labels']\n",
        "images43= np.load(dataset_path + \"/s4_wel_images.npz\")['images'] #50\n",
        "labels43 = np.load(dataset_path + \"/s4_wel_labels.npz\")['labels']\n",
        "\n",
        "images51 = np.load(dataset_path + \"/s5_count_images.npz\")['images'] #50\n",
        "labels51 = np.load(dataset_path + \"/s5_count_labels.npz\")['labels']\n",
        "images52 = np.load(dataset_path + \"/s5_ka_images.npz\")['images'] #50\n",
        "labels52 = np.load(dataset_path + \"/s5_ka_labels.npz\")['labels']\n",
        "images53 = np.load(dataset_path + \"/s5_pa_images.npz\")['images'] #50\n",
        "labels53 = np.load(dataset_path + \"/s5_pa_labels.npz\")['labels']"
      ],
      "metadata": {
        "id": "9etyrMWdFyVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select the correct images for the test. Use the images from a patient that is not in the training dataset."
      ],
      "metadata": {
        "id": "ibftWbemyDhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = images21\n",
        "y_test = labels21"
      ],
      "metadata": {
        "id": "zm-wWZgbF6A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 7"
      ],
      "metadata": {
        "id": "8oVmttamF62-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=NUM_CLASSES)"
      ],
      "metadata": {
        "id": "9MkKDnGWGAil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the model"
      ],
      "metadata": {
        "id": "inEKnqNQyX_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "model_path = \"/content/drive/MyDrive/vocal_tract_segmentation/weights_cross_val/rete_paper_2val.keras\"\n",
        "\n",
        "best_model = tf.keras.models.load_model(model_path, compile=False)"
      ],
      "metadata": {
        "id": "dVYVdINYGIxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "wjFpyqmwyf1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = best_model.predict(x_test)\n",
        "print('prediction shape: {}'.format(predictions.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRNSPRbjGL7J",
        "outputId": "5cb4e989-fc65-4aa3-9088-1e0bab352aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 11s/step\n",
            "prediction shape: (80, 256, 256, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Postprocessing to feed the predictions to monai metrics library."
      ],
      "metadata": {
        "id": "5FjiJsu7yjys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_onehot = np.argmax(predictions, axis = -1)\n",
        "print('prediction shape: {}'.format(predictions.shape))\n",
        "predictions_onehot = tf.keras.utils.to_categorical(predictions_onehot, num_classes=7)\n",
        "print('prediction shape: {}'.format(predictions.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIE7TUJWGM4u",
        "outputId": "0b7e10d8-6db5-4407-8025-828064c433e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction shape: (80, 256, 256, 7)\n",
            "prediction shape: (80, 256, 256, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Convert predictions and labels to tensors\n",
        "predictions_tensor = torch.from_numpy(predictions_onehot)  # (n, 256, 256, 7)\n",
        "labels_tensor = torch.from_numpy(y_test)                   # (n, 256, 256, 7)"
      ],
      "metadata": {
        "id": "vYrxOxsROf_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del predictions_onehot, y_test, images11, labels11"
      ],
      "metadata": {
        "id": "ydD23tn7MtaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "predictions_tensor = predictions_tensor.to(device)\n",
        "labels_tensor = labels_tensor.to(device)"
      ],
      "metadata": {
        "id": "EtDZCnJaPIoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert from one-hot encoding to class indices\n",
        "predictions_classes = torch.argmax(predictions_tensor, dim=-1)  # (n, 256, 256)\n",
        "labels_classes = torch.argmax(labels_tensor, dim=-1)            # (n, 256, 256)"
      ],
      "metadata": {
        "id": "YoxFyzfBPPyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai"
      ],
      "metadata": {
        "id": "9Veep4EJR1oK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9658cb43-809f-431f-f4b8-d5bf205b7604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: monai in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predictions_tensor.permute(0, 3, 1, 2)  # (n, 7, 256, 256)\n",
        "y_true = labels_tensor.permute(0, 3, 1, 2)"
      ],
      "metadata": {
        "id": "j7IH-GZxIYOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dice Score"
      ],
      "metadata": {
        "id": "RDYUSrWhy2-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.metrics import DiceMetric\n",
        "\n",
        "# Initialize the Dice metric\n",
        "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
        "\n",
        "# Calculate the Dice score\n",
        "dice_score = dice_metric(y_pred, y_true)            # Convert from (n, 256, 256, 7) to (n, 7, 256, 256))\n",
        "print(f\"Dice Score: {dice_score.mean(dim=0)}\")"
      ],
      "metadata": {
        "id": "fKzab1a8PsAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9122116-cbc7-4edc-cfff-e6408b3304fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dice Score: tensor([0.9926, 0.8625, 0.8243, 0.6797, 0.9290, 0.9012, 0.9715],\n",
            "       device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IOU"
      ],
      "metadata": {
        "id": "_2vjr-gPy5x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the Dice score to IoU (Intersection over Union)\n",
        "iou_score = dice_score / (2 - dice_score)\n",
        "print(f\"IoU Score: {iou_score.mean(dim=0)}\")"
      ],
      "metadata": {
        "id": "nx3KX4xWPtjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b6dc92-fe45-4657-f217-d40bc0cc5c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IoU Score: tensor([0.9852, 0.7605, 0.7041, 0.5218, 0.8678, 0.8209, 0.9447],\n",
            "       device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy, precision, recall"
      ],
      "metadata": {
        "id": "cO-47RV1y8bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from monai.metrics import get_confusion_matrix, compute_confusion_matrix_metric\n",
        "\n",
        "# Function to calculate the confusion matrix in batches\n",
        "def calculate_metrics_in_batches(predictions_tensor, labels_tensor, batch_size, include_background=True):\n",
        "    # Verify that predictions_tensor and labels_tensor have the same length\n",
        "    assert predictions_tensor.shape[0] == labels_tensor.shape[0], \"Predictions and labels must have the same batch size\"\n",
        "\n",
        "    # Calculate the total number of batches\n",
        "    num_batches = (predictions_tensor.shape[0] + batch_size - 1) // batch_size\n",
        "\n",
        "    # Initialize the total confusion matrix\n",
        "    total_conf_matrix = None\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        # Extract the current batch\n",
        "        start_idx = i * batch_size\n",
        "        end_idx = min((i + 1) * batch_size, predictions_tensor.shape[0])\n",
        "        pred_batch = predictions_tensor[start_idx:end_idx].permute(0, 3, 1, 2)  # (B, C, H, W)\n",
        "        label_batch = labels_tensor[start_idx:end_idx].permute(0, 3, 1, 2)  # (B, C, H, W)\n",
        "\n",
        "        # Calculate the confusion matrix for the current batch\n",
        "        with torch.no_grad():  # Avoid consuming memory for the computational graph\n",
        "            conf_matrix = get_confusion_matrix(pred_batch, label_batch, include_background=include_background)\n",
        "\n",
        "        # Sum the confusion matrices\n",
        "        if total_conf_matrix is None:\n",
        "            total_conf_matrix = conf_matrix\n",
        "        else:\n",
        "            total_conf_matrix += conf_matrix\n",
        "\n",
        "    # Calculate the final metrics\n",
        "    precision = compute_confusion_matrix_metric(\"precision\", total_conf_matrix)\n",
        "    recall = compute_confusion_matrix_metric(\"recall\", total_conf_matrix)\n",
        "    accuracy = compute_confusion_matrix_metric(\"accuracy\", total_conf_matrix)\n",
        "\n",
        "    return precision, recall, accuracy\n",
        "\n",
        "# Example usage\n",
        "batch_size = 4  # Set an appropriate batch size\n",
        "precision, recall, accuracy = calculate_metrics_in_batches(predictions_tensor, labels_tensor, batch_size)\n",
        "\n",
        "# Print the final results\n",
        "print(f\"Precision: {precision.mean(dim=0)}\")\n",
        "print(f\"Recall: {recall.mean(dim=0)}\")\n",
        "print(f\"Accuracy: {accuracy.mean(dim=0)}\")"
      ],
      "metadata": {
        "id": "8RmVya7kIyS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0afdcf7e-0d41-428f-96bf-04b37e92d2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: tensor([0.9919, 0.7909, 0.7620, 0.6406, 0.9170, 0.8855, 0.9789],\n",
            "       device='cuda:0')\n",
            "Recall: tensor([0.9932, 0.9495, 0.8970, 0.7179, 0.9413, 0.9175, 0.9643],\n",
            "       device='cuda:0')\n",
            "Accuracy: tensor([0.9882, 0.9996, 0.9990, 0.9991, 0.9977, 0.9985, 0.9899],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results:\n",
        "Each metric is calculated separately for the 7 classes. All the metrics are consistent during the cross validation.\n",
        "\n",
        "The classes are:\n",
        "\n",
        "1. Background\n",
        "2. Upper lip\n",
        "3. Hard palate\n",
        "4. Soft palate\n",
        "5. Tongue\n",
        "6. Lower lip\n",
        "7. Head\n",
        "\n",
        "## Patient 4 Excluded:\n",
        "\n",
        "Dice Score: [0.9881, 0.7414, 0.7868, 0.4424, 0.8328, 0.8310, 0.9453]\n",
        "\n",
        "IoU Score: [0.9765, 0.5929, 0.6533, 0.2909, 0.7138, 0.7115, 0.8964]\n",
        "\n",
        "Precision: [0.9893, 0.6041, 0.7716, 0.3421, 0.7522, 0.7935, 0.9641]\n",
        "\n",
        "Recall: [0.9870, 0.9719, 0.8153, 0.6403, 0.9339, 0.8732, 0.9277]\n",
        "\n",
        "Accuracy: [0.9818, 0.9989, 0.9988, 0.9971, 0.9915, 0.9966, 0.9793]\n",
        "\n",
        "## Patient 1 Excluded:\n",
        "\n",
        "Dice Score: [0.9926, 0.8296, 0.7197, 0.6192, 0.9106, 0.9167, 0.9658]\n",
        "\n",
        "IoU Score: [0.9852, 0.7105, 0.5770, 0.4502, 0.8363, 0.8474, 0.9339]\n",
        "\n",
        "Precision: [0.9953, 0.7364, 0.6467, 0.4880, 0.8473, 0.9157, 0.9667]\n",
        "\n",
        "Recall: [0.9898, 0.9531, 0.8727, 0.8512, 0.9848, 0.9192, 0.9650]\n",
        "\n",
        "Accuracy: [0.9882, 0.9994, 0.9990, 0.9986, 0.9969, 0.9986, 0.9880]\n",
        "\n",
        "## Patient 2 Excluded:\n",
        "\n",
        "Dice Score: [0.9925, 0.8448, 0.8480, 0.5761, 0.9072, 0.9121, 0.9690]\n",
        "\n",
        "IoU Score: [0.9851, 0.7335, 0.7381, 0.4118, 0.8305, 0.8388, 0.9398]\n",
        "\n",
        "Precision: [0.9935, 0.7562, 0.8561, 0.4750, 0.8832, 0.8915, 0.9709]\n",
        "\n",
        "Recall: [0.9915, 0.9575, 0.8389, 0.7242, 0.9326, 0.9334, 0.9670]\n",
        "\n",
        "Accuracy: [0.9881, 0.9995, 0.9992, 0.9985, 0.9970, 0.9986, 0.9889]\n",
        "\n",
        
      ],
      "metadata": {
        "id": "zpKILW4lzCR1"
      }
    }
  ]
}

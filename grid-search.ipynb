{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10208448,"sourceType":"datasetVersion","datasetId":6309076}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Possible usefull dependencies\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nimport tensorflow.keras.layers as tfkl\nimport keras\n\nfrom datetime import datetime\nfrom dateutil.tz import gettz\n\nimport scipy\nimport cv2\nimport os\n","metadata":{"id":"yz5iaH2c_c9X","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:10:25.204371Z","iopub.execute_input":"2024-12-15T16:10:25.204722Z","iopub.status.idle":"2024-12-15T16:10:39.095149Z","shell.execute_reply.started":"2024-12-15T16:10:25.204691Z","shell.execute_reply":"2024-12-15T16:10:39.094236Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Load","metadata":{"id":"Fv3mhiP_H0Gz"}},{"cell_type":"markdown","source":"Dataset import from kaggle folder.","metadata":{"id":"XM4jksxsP5rI","outputId":"0677f58d-6283-439d-9591-d6d3fb113562"}},{"cell_type":"code","source":"dataset_path = \"/kaggle/input/dataset-1/Dataset_new_new\"","metadata":{"id":"R3ghtYldQGx-","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:10:39.099974Z","iopub.execute_input":"2024-12-15T16:10:39.100242Z","iopub.status.idle":"2024-12-15T16:10:39.104389Z","shell.execute_reply.started":"2024-12-15T16:10:39.100218Z","shell.execute_reply":"2024-12-15T16:10:39.103283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nimages1 = np.load(dataset_path + \"/s1_micro_images.npz\")['images']\nlabels1 = np.load(dataset_path + \"/s1_micro_labels.npz\")['labels']\nimages2 = np.load(dataset_path + \"/s1_segre_images.npz\")['images']\nlabels2 = np.load(dataset_path + \"/s1_segre_labels.npz\")['labels']\nimages3 = np.load(dataset_path + \"/s1_top_images.npz\")['images']\nlabels3 = np.load(dataset_path + \"/s1_top_labels.npz\")['labels']\nimages4 = np.load(dataset_path + \"/s2_micro_images.npz\")['images']\nlabels4 = np.load(dataset_path + \"/s2_micro_labels.npz\")['labels']\nimages5 = np.load(dataset_path + \"/s2_segre_images.npz\")['images']\nlabels5 = np.load(dataset_path + \"/s2_segre_labels.npz\")['labels']\nimages6 = np.load(dataset_path + \"/s2_top_images.npz\")['images']\nlabels6 = np.load(dataset_path + \"/s2_top_labels.npz\")['labels']\nimages7 = np.load(dataset_path + \"/s4_micro_images.npz\")['images']\nlabels7 = np.load(dataset_path + \"/s4_micro_labels.npz\")['labels']\nimages8 = np.load(dataset_path + \"/s4_pata_images.npz\")['images']\nlabels8 = np.load(dataset_path + \"/s4_pata_labels.npz\")['labels']\nimages9 = np.load(dataset_path + \"/s4_wel_images.npz\")['images']\nlabels9 = np.load(dataset_path + \"/s4_wel_labels.npz\")['labels']","metadata":{"id":"BKUG7nIAQogg","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:10:48.727566Z","iopub.execute_input":"2024-12-15T16:10:48.727910Z","iopub.status.idle":"2024-12-15T16:10:54.047837Z","shell.execute_reply.started":"2024-12-15T16:10:48.727883Z","shell.execute_reply":"2024-12-15T16:10:54.046860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train = np.concatenate((images1, images2, images3, images4, images5, images6, images7, images8, images9))","metadata":{"id":"nHjoEnigSZfe","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:10:59.722462Z","iopub.execute_input":"2024-12-15T16:10:59.722748Z","iopub.status.idle":"2024-12-15T16:10:59.776908Z","shell.execute_reply.started":"2024-12-15T16:10:59.722726Z","shell.execute_reply":"2024-12-15T16:10:59.776229Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train = np.concatenate((labels1, labels2, labels3, labels4, labels5, labels6, labels7, labels8, labels9))","metadata":{"id":"ky-fz-t9Tb4x","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:11:05.094078Z","iopub.execute_input":"2024-12-15T16:11:05.094412Z","iopub.status.idle":"2024-12-15T16:11:05.155364Z","shell.execute_reply.started":"2024-12-15T16:11:05.094387Z","shell.execute_reply":"2024-12-15T16:11:05.154490Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(x_train[327, :, :, 0], cmap=\"gray\")\nplt.show()","metadata":{"id":"WRsCJyrTOC_p","outputId":"746f89a2-e1ab-4c1a-e1b0-356856206931"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(y_train[327, :, :, 0], cmap=\"gray\")\nplt.show()","metadata":{"id":"qvrVLylHOTIo","outputId":"034b1d04-f056-44ae-efc3-1138c04be5be","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:11:14.871949Z","iopub.execute_input":"2024-12-15T16:11:14.872369Z","iopub.status.idle":"2024-12-15T16:11:15.088812Z","shell.execute_reply.started":"2024-12-15T16:11:14.872335Z","shell.execute_reply":"2024-12-15T16:11:15.087607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images10 = np.load(dataset_path + \"/s5_count_images.npz\")['images']\nlabels10 = np.load(dataset_path + \"/s5_count_labels.npz\")['labels']\nimages11 = np.load(dataset_path + \"/s5_ka_images.npz\")['images']\nlabels11 = np.load(dataset_path + \"/s5_ka_labels.npz\")['labels']","metadata":{"id":"pGOuSxQfUKDo","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:11:22.526318Z","iopub.execute_input":"2024-12-15T16:11:22.526643Z","iopub.status.idle":"2024-12-15T16:11:23.165828Z","shell.execute_reply.started":"2024-12-15T16:11:22.526616Z","shell.execute_reply":"2024-12-15T16:11:23.164914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_val = np.concatenate((images10, images11))\ny_val = np.concatenate((labels10, labels11))","metadata":{"id":"BZ80ktQYUfVZ","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:11:26.290957Z","iopub.execute_input":"2024-12-15T16:11:26.291309Z","iopub.status.idle":"2024-12-15T16:11:26.314664Z","shell.execute_reply.started":"2024-12-15T16:11:26.291281Z","shell.execute_reply":"2024-12-15T16:11:26.313658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(x_val[2, :, :, 0], cmap=\"gray\")\nplt.show()","metadata":{"id":"mXgtwI79Unbe","outputId":"dc7b07fe-cadc-4b73-ad88-eb67d885fa1e","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:11:31.461408Z","iopub.execute_input":"2024-12-15T16:11:31.461749Z","iopub.status.idle":"2024-12-15T16:11:31.659083Z","shell.execute_reply.started":"2024-12-15T16:11:31.461722Z","shell.execute_reply":"2024-12-15T16:11:31.658134Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(y_val[2, :, :, 0], cmap=\"gray\")\nplt.show()","metadata":{"id":"B_MWDHUbUpol","outputId":"5a603757-9f8b-44bc-e60f-a1aec7911d83","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:11:35.844533Z","iopub.execute_input":"2024-12-15T16:11:35.844847Z","iopub.status.idle":"2024-12-15T16:11:36.001209Z","shell.execute_reply.started":"2024-12-15T16:11:35.844823Z","shell.execute_reply":"2024-12-15T16:11:36.000343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images12 = np.load(dataset_path + \"/s5_pa_images.npz\")['images']\nlabels12 = np.load(dataset_path + \"/s5_pa_labels.npz\")['labels']","metadata":{"id":"Sea7jla2Uzo_","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:11:41.150003Z","iopub.execute_input":"2024-12-15T16:11:41.151114Z","iopub.status.idle":"2024-12-15T16:11:41.476495Z","shell.execute_reply.started":"2024-12-15T16:11:41.151086Z","shell.execute_reply":"2024-12-15T16:11:41.475731Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_test = images12\ny_test = labels12","metadata":{"id":"m1Ck1Ey6U5V_","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:11:45.360684Z","iopub.execute_input":"2024-12-15T16:11:45.360997Z","iopub.status.idle":"2024-12-15T16:11:45.365193Z","shell.execute_reply.started":"2024-12-15T16:11:45.360973Z","shell.execute_reply":"2024-12-15T16:11:45.364081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('x_train shape', x_train.shape)\nprint('y_train shape', y_train.shape)\nprint('x_val shape', x_val.shape)\nprint('y_val shape', y_val.shape)\nprint('x_test shape', x_test.shape)\nprint('y_test shape', y_test.shape)","metadata":{"id":"7krksz0TVdy3","outputId":"85375719-eabc-4a30-f935-bbf870ef2e24","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:11:49.084370Z","iopub.execute_input":"2024-12-15T16:11:49.084680Z","iopub.status.idle":"2024-12-15T16:11:49.090374Z","shell.execute_reply.started":"2024-12-15T16:11:49.084656Z","shell.execute_reply":"2024-12-15T16:11:49.089397Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NUM_CLASSES = 7","metadata":{"id":"dw7pcLHyMJWC","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:11:52.910526Z","iopub.execute_input":"2024-12-15T16:11:52.910814Z","iopub.status.idle":"2024-12-15T16:11:52.915215Z","shell.execute_reply.started":"2024-12-15T16:11:52.910792Z","shell.execute_reply":"2024-12-15T16:11:52.913955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train = tf.keras.utils.to_categorical(y_train, num_classes=NUM_CLASSES)\ny_val = tf.keras.utils.to_categorical(y_val, num_classes=NUM_CLASSES)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=NUM_CLASSES)","metadata":{"id":"lY5OPRqhMExh"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('y_train shape', y_train.shape)\nprint('y_val shape', y_val.shape)\nprint('y_test shape', y_test.shape)","metadata":{"id":"UK5gkmqoMOYH","outputId":"704be45b-899d-4394-b22d-59cc4e0bf4ef"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Label count\nExtraction of mean values of number of pixels in each class in order to set the inital weights.","metadata":{"id":"ArKwR2uvH_wx"}},{"cell_type":"code","source":"label_count = np.zeros([7, 1])\n\nfor i in range(np.size(y_train, 3)):\n  for j in range(np.size(y_train, 0)):\n    label_count[i] = label_count[i] + np.sum(y_train[j, :, :, i])\n\nlabel_count = label_count/np.size(y_train, 0)\nlabel_count","metadata":{"id":"-E2xKki29_WP","outputId":"7d435716-ddef-4fc1-fb50-4f08df1b85f5"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_mean_values = {\"BKG\": 51575.88414634,\n           \"UL\": 103.51676829,\n           \"HP\": 150.63567073,\n           \"SP\": 101.21493902,\n           \"TO\": 1141.98018293,\n           \"LL\": 548.25304878,\n           \"HE\": 11914.5152439\n           }\nprint(label_mean_values)","metadata":{"id":"J2CBymEpCu_X","outputId":"c60924f7-4af8-4cc2-826e-9ba23263dc78"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute weights for the weighted loss\nimport numpy as np\n\n# Calculate the inverse frequency\nclass_weights = 1.0 / label_count.flatten()\n\n# Normalize the weights (optional but recommended)\nnormalized_weights = class_weights * NUM_CLASSES / np.sum(class_weights)\n\nprint(\"Class weights:\", class_weights)\nprint(\"Normalized class weights:\", normalized_weights)","metadata":{"id":"JanH3n_0Q3vD","outputId":"e38ef48f-fce8-483a-cc6b-3b8b87546e51"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#Dataset creation","metadata":{"id":"66sPVr4QVZTz"}},{"cell_type":"code","source":"BATCH_SIZE = 8\n\n# Create dataset where each item is a tuple (image, image_segmented)\ntrain_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(\n    lambda x, y: (tf.cast(x, tf.float32), tf.cast(y, tf.float32))\n)\n\nval_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val)).map(\n    lambda x, y: (tf.cast(x, tf.float32), tf.cast(y, tf.float32))\n)\n\ntest_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).map(\n    lambda x, y: (tf.cast(x, tf.float32), tf.cast(y, tf.float32))\n)\n\n# Shaffle and batch train_ds\ntrain_ds = train_ds.shuffle(buffer_size=BATCH_SIZE * 16)  # mix the data\ntrain_ds = train_ds.batch(BATCH_SIZE, drop_remainder=False)  # create batch\ntrain_ds = train_ds.prefetch(tf.data.AUTOTUNE)  # improve the computational performance\n\n# Batch val_ds\nval_ds = val_ds.batch(BATCH_SIZE, drop_remainder=False)\nval_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n\n# Take 1 batch as example\nfor batch in train_ds.take(1):\n    print(batch[0].shape)  # it should be (BATCH_SIZE, H, W, C)\n    print(batch[1].shape)  # it should be (BATCH_SIZE, H, W, NUM_CLASSES)","metadata":{"id":"c4w4LEzFM3EZ","outputId":"64086721-bad3-4552-f01a-add9f4986fad"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del x_train, y_train, x_val, y_val, x_test, y_test","metadata":{"id":"BZ-8NtgISXmj"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install keras-cv --upgrade","metadata":{"id":"BLjBlO0MNNAG","outputId":"9d77abd0-7f83-4077-e324-c35af0a6bb37"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed= 42","metadata":{"id":"d8qOtbz1WM0_"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@tf.function\ndef random_flip(image, label, seed=seed):\n    \"\"\"Consistent random horizontal flip for both image and label.\"\"\"\n\n    # Determine flip probability\n    flip_prob = tf.random.uniform([], seed=seed)\n    # print(f\"flip_horizontal: {flip_prob}\")\n\n    # Image flip\n    image = tf.cond(\n        flip_prob > 0.5,\n        lambda: tf.image.flip_left_right(image),\n        lambda: image\n    )\n\n    # Segmentation flip (label)\n    label = tf.cond(\n        flip_prob > 0.5,\n        lambda: tf.image.flip_left_right(label),\n        lambda: label\n    )\n\n    return image, label","metadata":{"id":"2_msQ-leNZwk"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@tf.function\ndef random_brightness(image, label, max_delta=0.2, seed=seed):\n    \"\"\"Increase or decrease brightness by a random factor.\"\"\"\n    # Determine the probability of modifying brightness\n    brightness_prob = tf.random.uniform([], minval=0., maxval=1., seed=seed)\n    #print(f\"brightenss: {brightness_prob}\")\n\n    # Modify brightness\n    image = tf.cond(\n        brightness_prob > 0.5,\n        lambda: tf.image.random_brightness(image, max_delta=max_delta, seed=seed),\n        lambda: image\n    )\n\n    return image, label","metadata":{"id":"wXIl_Hu8Ndu9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@tf.function\ndef random_crop(image, label, crop_size=(56, 112), seed=None):\n    \"\"\"Random crop on image and label\"\"\"\n\n    # Determine crop probability\n    crop_prob = tf.random.uniform([], minval=0., maxval=1., seed=seed)\n\n    # get image and label shape (batch_size, height, width, channels)\n    image_shape = tf.shape(image)\n    label_shape = tf.shape(label)\n\n    # Get channel number\n    image_channels = image_shape[-1]\n    label_channels = label_shape[-1]\n\n    batch_size = image_shape[0]\n    target_size = (64, 128)\n\n    # Random crop application with one probability\n    image = tf.cond(\n        crop_prob > 0.5,\n        lambda: tf.image.random_crop(image, size=[batch_size,crop_size[0], crop_size[1], image_channels], seed=seed),\n        lambda: image\n    )\n\n    label = tf.cond(\n        crop_prob > 0.5,\n        lambda: tf.image.random_crop(label, size=[batch_size, crop_size[0], crop_size[1], label_channels], seed=seed),\n        lambda: label\n    )\n\n    image = tf.image.resize(image, target_size)\n    label = tf.image.resize(label, target_size)\n\n    return image, label","metadata":{"id":"oCzTgw-NNevA"},"outputs":[],"execution_count":null},{
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def random_contrast(image, label, lower=0.5, upper=1.5, seed=seed):\n",
        "    \"\"\"Applies a random contrast adjustment to the image.\"\"\"\n",
        "\n",
        "    # Determine the probability of contrast adjustment\n",
        "    contrast_prob = tf.random.uniform([], minval=0., maxval=1., seed=seed)\n",
        "\n",
        "    # Modify the contrast\n",
        "    image = tf.cond(\n",
        "        contrast_prob > 0.5,\n",
        "        lambda: tf.image.random_contrast(image, lower=lower, upper=upper, seed=seed),\n",
        "        lambda: image\n",
        "    )\n",
        "\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "9znaZAxKbOOo"
      },
      "execution_count": null,
      "outputs": []
    },{"cell_type":"code","source":"@tf.function\ndef augment_image(image, label, seed=seed):\n    \"\"\"Apply augmentations.\"\"\"\n    # Horizontal flip\n    image, label = random_flip(image, label, seed=seed)\n\n    # Adjust brightness\n    image, label = random_brightness(image, label, seed=seed)\n\n    # Contrast distorsion\n    image, label = random_contrast(image, label, seed=seed)\n\n    return image, label","metadata":{"id":"AWGWsepzQwWF"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = train_ds.map(\n    lambda x, y: augment_image(x, y, seed=seed),  # before apply augmentation and then  normalization\n    num_parallel_calls=tf.data.AUTOTUNE\n)","metadata":{"id":"oIQMAItZQaNv"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preprocessing: sono già normalizzate tra 0 e 1\n","metadata":{"id":"tDbqSrAt6AHr"}},{"cell_type":"markdown","source":"## Dataset Visualization: da fare se vogliamo\n\n","metadata":{"id":"Z6k-wliDmMI0"}},{"cell_type":"markdown","source":"## Loss Function\n\nCross Entropy:  $\\, L_{CE} = -\\sum_{c=1}^{C} \\frac{1}{N} \\sum_{i=1}^{N} g_i^c\\,log\\,p_i^c \\quad$ [[1]](https://www.sciencedirect.com/science/article/pii/S1361841521000815)\n\nwhere:\n* $C$ = n°classes\n* $N$ = n°pixels of image (256x256)\n* $g_i^c$ = value of the $i^{th}$ pixel of the $c^{th}$ class of the ground truth label\n* $p_i^c$ = value of the $i^{th}$ pixel of the $c^{th}$ class of the predicted label","metadata":{"id":"QK_miT960Gs7"}},{"cell_type":"code","source":"def cross_entropy(num_classes):\n    def loss(y_true, y_pred): #called each iteration (step)\n\n        if len(y_pred.shape) == 4: #2D image\n            axis = (1,2)\n        elif len(y_pred.shape) == 5: #3D volume\n            axis == (1,2,3)\n\n        y_true = tf.cast(y_true, dtype = tf.float32)\n        y_pred = tf.cast(y_pred, dtype = tf.float32)\n\n        loss_image = 0.0\n        loss_ce = 0.0\n\n        for c in range(num_classes):\n\n            loss_image = tf.math.add(-1*(tf.math.reduce_mean(tf.math.multiply(y_true[...,c], tf.math.log(y_pred[...,c] + 1e-9)), axis = axis)), loss_image)\n\n        loss_ce = tf.math.reduce_mean(loss_image)\n\n        return loss_ce\n\n    return loss\n\n#in model.compile can also be set the default tf.keras.losses.CategoricalCrossentropy()","metadata":{"id":"ZNQec2uRnaTs"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"weighted cross entropy loss\n","metadata":{"id":"FZkUK249OFB6"}},{"cell_type":"code","source":"def weighted_cross_entropy(num_classes, class_weights):\n    \"\"\"\n    Weighted categorical cross-entropy loss with class weights for 2D/3D inputs.\n\n    Args:\n    - num_classes (int): Number of classes.\n    - class_weights (list or array): Weights for each class. Length must match `num_classes`.\n\n    Returns:\n    - A callable loss function.\n    \"\"\"\n    def loss(y_true, y_pred):\n        # Assicurati che y_true e y_pred siano float32\n        y_true = tf.cast(y_true, dtype=tf.float32)\n        y_pred = tf.cast(y_pred, dtype=tf.float32)\n\n        # Prevenzione di log(0) con epsilon\n        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n\n        # Calcolo della cross-entropy ponderata per ogni classe\n        weighted_loss = 0.0\n        for c in range(num_classes):\n            weight = class_weights[c]\n            class_loss = -y_true[..., c] * tf.math.log(y_pred[..., c])\n            weighted_loss += weight * class_loss\n\n        # Media su tutti gli assi spaziali e il batch\n        loss_ce = tf.reduce_mean(weighted_loss)\n        return loss_ce\n\n    return loss","metadata":{"id":"MVOOukDhOCHt"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow.keras.backend as K\n\ndef dice_loss(y_true, y_pred, smooth=K.epsilon()):\n    \"\"\"\n    Calcola la Dice Loss, che misura la similarità tra le immagini segmentate e quelle vere.\n\n    Args:\n    - y_true: Etichette vere (ground truth) in formato one-hot encoded o etichette binarie.\n    - y_pred: Predizioni del modello in formato one-hot encoded o probabilità.\n    - smooth: Un piccolo valore per evitare la divisione per zero.\n\n    Returns:\n    - La Dice Loss.\n    \"\"\"\n    # Assicurati che le predizioni siano trattate come probabilità\n    #y_pred = K.clip(y_pred, 0, 1)\n\n    # Calcolo della Dice Similarity Coefficient (DSC)\n    intersection = K.sum(y_true * y_pred, axis=(1, 2, 3))  # Somma per ogni classe su tutte le immagini\n    union = K.sum(y_true, axis=(1, 2, 3)) + K.sum(y_pred, axis=(1, 2, 3))  # Somma delle aree di verità a terra e previste\n    dice = (2.0 * intersection + smooth) / (union + smooth)  # Formula della Dice Similarity\n\n    return 1 - dice  # La Dice Loss è 1 meno il DSC (perché vogliamo minimizzare la perdita)","metadata":{"id":"_hVx08Wn6kId"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def combined_loss(num_classes, class_weights, alpha=0.5, beta=0.5, smooth=K.epsilon()):\n    \"\"\"\n    Combina la Weighted Cross-Entropy Loss e la Dice Loss in una funzione di perdita composita.\n\n    Args:\n    - num_classes (int): Numero di classi.\n    - class_weights (list or array): Pesi per ogni classe per la cross-entropy.\n    - alpha (float): Ponderazione per la Weighted Cross-Entropy Loss.\n    - beta (float): Ponderazione per la Dice Loss.\n    - smooth (float): Piccolo valore per evitare la divisione per zero nella Dice Loss.\n\n    Returns:\n    - Una funzione di perdita combinata.\n    \"\"\"\n    # Recupera le funzioni di perdita individuali\n    wce_loss = weighted_cross_entropy(num_classes, class_weights)\n\n    def loss(y_true, y_pred):\n        # Calcola le singole perdite\n        loss_wce = wce_loss(y_true, y_pred)\n        loss_dice = dice_loss(y_true, y_pred, smooth=smooth)\n\n        # Combina le perdite con i pesi\n        combined = alpha * loss_wce + beta * loss_dice\n        return combined\n\n    return loss","metadata":{"id":"CIuyYSi6CwRC"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"focal_loss = tf.keras.losses.CategoricalFocalCrossentropy(\n    alpha=class_weights,\n    gamma=2.0,\n    name='categorical_focal_crossentropy'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Metric\n\n\n\nMean Dice: $\\, DICE = \\frac{1}{C}  \\sum_{c = 1}^{C} \\frac{2 \\lvert S_g^c \\cap S_p^c \\rvert}{\\lvert S_g^c \\rvert + \\lvert S_p^c \\rvert} = \\frac{2\\,\\sum_{c=1}^{C}\\sum_{i=1}^{N}g_i^c\\,p_i^c}{\\sum_{c=1}^{C}\\sum_{i=1}^{N}g_i^c \\,+\\, \\sum_{c=1}^{C}\\sum_{i=1}^{N}p_i^c  } \\quad$ [[3]](https://bmcmedimaging.biomedcentral.com/track/pdf/10.1186/s12880-015-0068-x.pdf)","metadata":{"id":"G27XDd3lZpPi"}},{"cell_type":"code","source":"class Mean_DICE(keras.metrics.Metric):\n    def __init__(self, num_classes, name='Mean_DICE', smooth_factor=1e-9, **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.num_classes = num_classes\n        self.smooth_factor = smooth_factor\n\n        # Variabili accumulative\n        self.total_dice = self.add_weight(name=\"total_dice\", initializer=\"zeros\", dtype=tf.float32)\n        self.num_samples = self.add_weight(name=\"num_samples\", initializer=\"zeros\", dtype=tf.float32)\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = tf.cast(y_true, dtype=tf.float32)\n        y_pred = tf.cast(y_pred, dtype=tf.float32)\n\n        if len(y_pred.shape) == 4:\n            axis = (1, 2)\n        elif len(y_pred.shape) == 5:\n            axis = (1, 2, 3)\n        else:\n            raise ValueError(\"y_pred must have 4 or 5 dimensions.\")\n\n        dice_classes = 0.0\n\n        for c in range(self.num_classes):\n            abs_label = tf.reduce_sum(y_true[..., c], axis=axis)\n            abs_pred = tf.reduce_sum(y_pred[..., c], axis=axis)\n\n            MD_batch_denom = abs_label + abs_pred + self.smooth_factor\n            MD_batch_num = 2 * tf.reduce_sum(y_true[..., c] * y_pred[..., c], axis=axis) + self.smooth_factor\n\n            dice_image = MD_batch_num / MD_batch_denom\n            dice_classes += dice_image\n\n        mean_dice = dice_classes / self.num_classes\n        batch_mean_dice = tf.reduce_mean(mean_dice)\n\n        # Aggiornamento delle variabili accumulative\n        self.total_dice.assign_add(batch_mean_dice)\n        self.num_samples.assign_add(1.0)\n\n    def result(self):\n        return self.total_dice / self.num_samples\n\n    def reset_states(self):\n        self.total_dice.assign(0.0)\n        self.num_samples.assign(0.0)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({'num_classes': self.num_classes, 'smooth_factor': self.smooth_factor})\n        return config\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n","metadata":{"id":"Kd5rou74ZjJa"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Architectures: questa è la rete che ho modificato, poi comunque possiamo usare anche altri paramentri oppure riutilizzare quella vecchia","metadata":{"id":"A594VyDIfLcK"}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.layers as tfkl\n\ndef residual_block(x, n_filters):\n  '''implementation of the residual block described in\n  https://www.sciencedirect.com/science/article/pii/S0169260721000201?via%3Dihub'''\n  shortcut = x\n\n  x = tfkl.BatchNormalization()(x)\n  x = tfkl.ReLU()(x)\n  x = tfkl.Conv2D(n_filters, 3, padding = 'same', activation = None)(x)\n\n  x = tfkl.BatchNormalization()(x)\n  x = tfkl.ReLU()(x)\n  x = tfkl.Conv2D(n_filters, 3, padding = 'same', activation = None)(x)\n\n  shortcut = tfkl.Conv2D(n_filters, 1, padding = 'same', activation = None)(shortcut)\n  shortcut = tfkl.BatchNormalization()(shortcut)\n\n  out = tfkl.Add()([shortcut, x])\n  return out\n\ndef decoder_block(x, n_filters, skip, dropout):\n  '''implementation of the decoder block described in\n  https://www.sciencedirect.com/science/article/pii/S0169260721000201?via%3Dihub'''\n  x = tfkl.Conv2DTranspose(n_filters, 1, strides=(2, 2), padding='same')(x)\n  x = tfkl.BatchNormalization()(x)\n\n  x = tfkl.Concatenate()([x, skip])\n  x = tfkl.Dropout(dropout)(x)\n\n  out = residual_block(x, n_filters)\n  return out\n\ndef encoder_block(x, n_filters, dropout):\n  '''implementation of the encoder block described in\n  https://www.sciencedirect.com/science/article/pii/S0169260721000201?via%3Dihub'''\n  skip = residual_block(x, n_filters)\n  x = tfkl.MaxPool2D(2)(skip)\n  x = tfkl.Dropout(dropout)(x)\n  return x, skip\n\ndef dilated_conv_block(x, filters):\n  '''implementation of the bottleneck described in\n  https://www.sciencedirect.com/science/article/pii/S0169260721000201?via%3Dihub'''\n  for dilation_rate in [1, 2, 4, 8]:\n      x = tfkl.Conv2D(filters, (3, 3), dilation_rate=dilation_rate, padding='same', activation='relu')(x)\n  return x\n\ndef improved_unet(x, num_classes, dropout, n_filter):\n  '''implementetion of the improved unet'''\n  x = residual_block(x, n_filter)\n\n  # encoder\n  x, skip1 = encoder_block(x, n_filter*2, dropout)\n  x, skip2 = encoder_block(x, n_filter*4, dropout)\n  x, skip3 = encoder_block(x, n_filter*8, dropout)\n  x, skip4 = encoder_block(x, n_filter*16, dropout)\n\n  # bottleneck\n  x = dilated_conv_block(x, n_filter*32)\n\n  # decoder\n  d1 = decoder_block(x, n_filter*16, skip4, dropout)\n  d2 = decoder_block(d1, n_filter*8, skip3, dropout)\n  d3 = decoder_block(d2, n_filter*4, skip2, dropout)\n  d4 = decoder_block(d3, n_filter*2, skip1, dropout)\n\n  resizing_layer = tf.keras.layers.Resizing(height=256, width=256, interpolation='bilinear')\n  up_d1 = resizing_layer(d1)\n  up_d2 = resizing_layer(d2)\n  up_d3 = resizing_layer(d3)\n\n  x = tfkl.Concatenate()([up_d1, up_d2, up_d3, d4])\n\n  # head\n  out = tfkl.Conv2D(num_classes, 1, padding=\"same\", activation = \"softmax\")(x)\n\n  return out","metadata":{"id":"ApxQs5uKqhg1"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Building & Callbacks","metadata":{"id":"jUBogRV5UOkI"}},{"cell_type":"code","source":"#Build Model --> instantiate the weights of the defined architecture according to the choosen mode\ndef build_model(\n    input_shape,\n    num_classes = 7,\n    learning_rate = 0.0001,\n    dropout = 0.5,\n    n_filter = 16,\n    augmentation = None,\n    seed = 42\n):\n    # Set the random seed for reproducibility\n    tf.random.set_seed(seed)\n\n    # Define the input layer\n    input_layer = tfkl.Input(shape=input_shape, name='Input')\n\n    # Apply optional data augmentation\n    if augmentation == None:\n        x = input_layer\n    else:\n        x = augmentation(input_layer)\n\n    output = improved_unet(x, NUM_CLASSES, dropout, n_filter)\n\n    # Define the model\n    model = tf.keras.Model(inputs=input_layer, outputs=output, name='Improved_UNET')\n\n    return model","metadata":{"id":"Hoa3R1qiP_bd"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# compile model","metadata":{"id":"Nj189dEEQHK-"}},{"cell_type":"code","source":"# lista con metriche per valutazione\nmetrics = [Mean_DICE(num_classes = 7)]","metadata":{"id":"B7ehawhkhLNA"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configure the Adam optimizer\nfrom pathlib import Path\nadam_optimizer = tf.keras.optimizers.Adam(\n    learning_rate=0.0001,  # Step size (α)\n    beta_1=0.9,            # Exponential decay rate for the first moment (β1)\n    beta_2=0.999,          # Exponential decay rate for the second moment (β2)\n    epsilon=1e-8           # Small constant to prevent division by zero (ε)\n)\n\n\n#Create a directory tree to neatly save the models\n\npath_output = '/kaggle/working/'\ntraining_path = os.path.join(path_output, 'Training_' + datetime.now(gettz(\"Europe/Rome\")).strftime(\"%Y-%m-%d-T%H:%M\"))\ncheckpoint_path = os.path.join(training_path, 'Checkpoints')\nbest_model_path = os.path.join(training_path, 'Best_Model')\n\nPath(training_path).mkdir(parents=True, exist_ok=True)\nPath(checkpoint_path).mkdir(parents=True, exist_ok=True)\nPath(best_model_path).mkdir(parents=True, exist_ok=True)","metadata":{"id":"VvmM_jMcQJzt"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# callbacks and build and fit function\nin this section the callback are initialized and a function that build the model and fit it is created. The latter is useful while computing the grid search because the hparams are given as input of the function.","metadata":{"id":"sK2z8xksS-Iw"}},{"cell_type":"code","source":"# callback for lr reducing\nReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.1,\n        patience=10,\n        verbose=1,\n        min_lr=1e-10\n    )\n\n#Callback to keep track of the model with the best validation Mean_DICE\npatience = 20\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', # qui lui dice di monitorare il dice, però nel paper monitorano la val_loss. per ora userei quella, poi cambiamo\n    mode='min',\n    patience=patience,\n    restore_best_weights=True\n)\n\n#Callback for the tensorboard monitoring\ntensorboard_callback = tf.keras.callbacks.TensorBoard(\n    log_dir=checkpoint_path,\n    histogram_freq=1,  # Registra gli istogrammi dei pesi\n    write_graph=False,  # Salva il grafo del modello\n    write_images=False  # Salva immagini per visualizzazioni\n)","metadata":{"id":"m0XaztwDo9Q7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"losses = ['combined: weighted and dice', 'dice_loss', 'focal_loss']\n\ndef build_and_fit(hparams):\n\n  adam_optimizer = tf.keras.optimizers.Adam(\n    learning_rate=0.0001,  # Step size (α)\n    beta_1=0.9,            # Exponential decay rate for the first moment (β1)\n    beta_2=0.999,          # Exponential decay rate for the second moment (β2)\n    epsilon=1e-8           # Small constant to prevent division by zero (ε)\n    )\n\n  model = build_model(input_shape = (256, 256, 1),\n                    num_classes = 7,\n                    learning_rate = 0.0001,\n                    dropout = hparams[HP_DROPOUT],\n                    n_filter = hparams[HP_N_FILTERS],\n                    augmentation = None,\n                    seed = 42)\n\n  # Get the loss function based on the hparams value\n  loss_function = hparams[HP_LOSS]\n  if loss_function == 'combined: weighted and dice':\n    loss_function = combined_loss(num_classes=NUM_CLASSES, class_weights=normalized_weights, alpha=0.6, beta=0.4)\n  elif loss_function == 'dice_loss':\n    loss_function = dice_loss\n  elif loss_function == 'focal_loss':\n    loss_function = focal_loss\n  else:\n    raise ValueError(f\"Invalid loss function: {loss_function}\")\n\n  model.compile(loss = loss_function,  # Use the resolved loss function\n                  optimizer = adam_optimizer,\n                  metrics = metrics)\n  history = model.fit(train_ds,\n                    validation_data=val_ds,\n                    epochs=100,\n                    callbacks=[early_stopping, ReduceLROnPlateau, tensorboard_callback, hp.KerasCallback(hparams_path, hparams)])\n  return history.history['val_Mean_DICE'][-1], model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Training & Evaluation","metadata":{"id":"cXjMj7fLZ205"}},{"cell_type":"markdown","source":"# Creation of the hparam for tensorboard and set-up of the grid search","metadata":{}},{"cell_type":"code","source":"from tensorboard.plugins.hparams import api as hp\n\nhparams_path = os.path.join(checkpoint_path, 'hparams')\nPath(hparams_path).mkdir(parents=True, exist_ok=True)\n\nHP_DROPOUT = hp.HParam('dropout_rate', hp.RealInterval(0.1, 0.5))\nHP_LOSS = hp.HParam('loss_function', hp.Discrete(['dice_loss', 'focal_loss','combined: weighted and dice']))\nHP_N_FILTERS = hp.HParam('number_of_filters', hp.Discrete([8, 16]))\nMETRIC_DICE = 'val_mean_dice'\n\nwith tf.summary.create_file_writer(hparams_path).as_default():\n  hp.hparams_config(\n    hparams=[HP_DROPOUT, HP_LOSS, HP_N_FILTERS],\n    metrics=[hp.Metric(METRIC_DICE, display_name='dice')],\n  )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run(run_dir, hparams):\n  with tf.summary.create_file_writer(run_dir).as_default():\n    hp.hparams(hparams)  # record the values used in this trial\n    val_mean_dice, model = build_and_fit(hparams)\n    tf.summary.scalar(METRIC_DICE, val_mean_dice, step=1)\n  return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model fit with different hparams","metadata":{}},{"cell_type":"code","source":"!kill $(sudo lsof -t -i:6006)","metadata":{"id":"QQucVceWJ2gL","outputId":"56ae257c-b3a1-410d-c326-98bba50957f7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#model.fit --> actual training of the model using back-propagation for updating weights\n#model.fit --> actual training of the model using back-propagation for updating weights\nsession_num = 0\nfor dropout in [0, 0.2, 0.5]:\n  for i, loss in enumerate(losses):\n    for n_filter in [8, 16]:\n      print(f'dropout: {dropout}, loss: {loss}, n_filter: {n_filter}')\n      hparams = {\n          HP_DROPOUT: dropout,\n          HP_LOSS: loss,\n          HP_N_FILTERS: n_filter\n      }\n      run_name = \"run-%d\" % session_num\n      print('--- Starting trial: %s' % run_name)\n      print({h.name: hparams[h] for h in hparams})\n      model = run(hparams_path + '/' + run_name, hparams)\n      model.save(f'dropout_{dropout}_loss_{i+1}_n_filter_{n_filter}.keras')\n      session_num += 1\n      del model\n      tf.keras.backend.clear_session()","metadata":{"id":"Wbn1ZbaxuLXq","outputId":"09f21155-3dce-443f-8fe0-cf7aba779a85"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plotting the grid search in tensorboard","metadata":{}},{"cell_type":"code","source":"%load_ext tensorboard","metadata":{"id":"zd6-OfzSGjkt"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%tensorboard --logdir \"$checkpoint_path\"","metadata":{"id":"8eV-E5aoDHT1","outputId":"2597b858-e6e6-4828-85f4-4127c4c94cab"},"outputs":[],"execution_count":null}]}
